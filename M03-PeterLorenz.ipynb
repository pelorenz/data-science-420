{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 03\n",
    "# Peter Lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminaries\n",
    "\n",
    "Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Display multiple cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Do not truncate numpy arrays\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split data from Milestone 1 into training and testing\n",
    "In this section, we split the prepared data from Milestone 1 into training and test data sets. But first we must reload and clean this data following our procedure in Milestone 1.\n",
    "\n",
    "### Read and clean data (from Milestone 1)\n",
    "Here we follow the steps taken in Milestone 1 to prepare our data for modeling. Commentary is kept to a minimum as these matters have already been discussed in Milestone 1. Also, cell output is kept to the minimum necessary to confirm that the code is functioning as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1566, 590)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>...</th>\n",
       "      <th>s581</th>\n",
       "      <th>s582</th>\n",
       "      <th>s583</th>\n",
       "      <th>s584</th>\n",
       "      <th>s585</th>\n",
       "      <th>s586</th>\n",
       "      <th>s587</th>\n",
       "      <th>s588</th>\n",
       "      <th>s589</th>\n",
       "      <th>s590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3095.780</td>\n",
       "      <td>2465.140</td>\n",
       "      <td>2230.422</td>\n",
       "      <td>1463.661</td>\n",
       "      <td>0.829</td>\n",
       "      <td>100.000</td>\n",
       "      <td>102.343</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.497</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>208.204</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4.445</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>208.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2932.610</td>\n",
       "      <td>2559.940</td>\n",
       "      <td>2186.411</td>\n",
       "      <td>1698.017</td>\n",
       "      <td>1.510</td>\n",
       "      <td>100.000</td>\n",
       "      <td>95.488</td>\n",
       "      <td>0.124</td>\n",
       "      <td>1.444</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>82.860</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3.175</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.015</td>\n",
       "      <td>82.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2988.720</td>\n",
       "      <td>2479.900</td>\n",
       "      <td>2199.033</td>\n",
       "      <td>909.793</td>\n",
       "      <td>1.320</td>\n",
       "      <td>100.000</td>\n",
       "      <td>104.237</td>\n",
       "      <td>0.122</td>\n",
       "      <td>1.488</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>73.843</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2.054</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.004</td>\n",
       "      <td>73.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3032.240</td>\n",
       "      <td>2502.870</td>\n",
       "      <td>2233.367</td>\n",
       "      <td>1326.520</td>\n",
       "      <td>1.533</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.397</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.503</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.104</td>\n",
       "      <td>99.303</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.004</td>\n",
       "      <td>73.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2946.250</td>\n",
       "      <td>2432.840</td>\n",
       "      <td>2233.367</td>\n",
       "      <td>1326.520</td>\n",
       "      <td>1.533</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.397</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.529</td>\n",
       "      <td>0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>44.008</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3.828</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005</td>\n",
       "      <td>44.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        s1       s2       s3       s4    s5      s6      s7    s8    s9  \\\n",
       "0 3095.780 2465.140 2230.422 1463.661 0.829 100.000 102.343 0.125 1.497   \n",
       "1 2932.610 2559.940 2186.411 1698.017 1.510 100.000  95.488 0.124 1.444   \n",
       "2 2988.720 2479.900 2199.033  909.793 1.320 100.000 104.237 0.122 1.488   \n",
       "3 3032.240 2502.870 2233.367 1326.520 1.533 100.000 100.397 0.123 1.503   \n",
       "4 2946.250 2432.840 2233.367 1326.520 1.533 100.000 100.397 0.123 1.529   \n",
       "\n",
       "     s10  ...  s581    s582  s583  s584  s585   s586  s587  s588  s589    s590  \n",
       "0 -0.001  ... 0.006 208.204 0.502 0.022 0.005  4.445 0.010 0.020 0.006 208.204  \n",
       "1  0.004  ... 0.015  82.860 0.496 0.016 0.004  3.175 0.058 0.048 0.015  82.860  \n",
       "2 -0.012  ... 0.004  73.843 0.499 0.010 0.003  2.054 0.020 0.015 0.004  73.843  \n",
       "3 -0.003  ...   nan     nan 0.480 0.477 0.104 99.303 0.020 0.015 0.004  73.843  \n",
       "4  0.017  ... 0.005  44.008 0.495 0.019 0.004  3.828 0.034 0.015 0.005  44.008  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1566, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>\"19/07/2008</td>\n",
       "      <td>12:32:00\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"19/07/2008</td>\n",
       "      <td>13:17:00\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>\"19/07/2008</td>\n",
       "      <td>14:43:00\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>\"19/07/2008</td>\n",
       "      <td>15:22:00\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>\"19/07/2008</td>\n",
       "      <td>17:53:00\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   result         date       time\n",
       "0      -1  \"19/07/2008  12:32:00\"\n",
       "1       1  \"19/07/2008  13:17:00\"\n",
       "2      -1  \"19/07/2008  14:43:00\"\n",
       "3      -1  \"19/07/2008  15:22:00\"\n",
       "4      -1  \"19/07/2008  17:53:00\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Internet location of the data set and labels\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\"\n",
    "labels_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\"\n",
    "\n",
    "# Download sensor data and labels into a dataframe object, specify python engine for regex\n",
    "sensor_data = pd.read_csv(url, sep='\\s{1,}', engine='python')\n",
    "sensor_labels_data = pd.read_csv(labels_url, sep='\\s{1,}', engine='python')\n",
    "\n",
    "# Generate index-based column names for the sensor data set\n",
    "sensor_data.columns = list('s' + str(idx + 1) for idx in range(0, sensor_data.shape[1]))\n",
    "\n",
    "# Assign column names to the labels\n",
    "sensor_labels_data.columns = ['result', 'date', 'time']\n",
    "\n",
    "# Save the original data frame for future reference as we modify its contents\n",
    "sensor_data_orig = sensor_data\n",
    "\n",
    "# Confirm that data set and labels are loaded\n",
    "print('Sensor data set:')\n",
    "sensor_data.shape\n",
    "sensor_data.head()\n",
    "\n",
    "print('Sensor labels:')\n",
    "sensor_labels_data.shape\n",
    "sensor_labels_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with more than 5% NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 538)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count NaN's per column\n",
    "df_na = sensor_data.isna().sum()\n",
    "\n",
    "# Identify columns above cutoff of 5% NaN's\n",
    "nan_5_pct = df_na[df_na > 0.05 * sensor_data.shape[0]]\n",
    "\n",
    "# Drop columns with more than 5% NaN's\n",
    "sensor_data = sensor_data.drop(list(nan_5_pct.index), axis=1)\n",
    "sensor_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute fields with NaN in the remaining columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute and replace missing values using column median\n",
    "sensor_data = sensor_data.replace('?', \n",
    "                                  np.NaN).apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns with zero variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with zero variance\n",
    "zero_variance_cols = np.array(sensor_data.columns[sensor_data.var() == 0])\n",
    "\n",
    "# Drop columns with zero variance\n",
    "sensor_data = sensor_data.drop(zero_variance_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns consisting of more than 20% zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 401)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count zeroes per column\n",
    "zero_counts = sensor_data[sensor_data == 0].count(axis=0)\n",
    "\n",
    "# Identify columns above cutoff of 20% zero\n",
    "zero_20_pct = zero_counts[zero_counts > 0.2 * sensor_data.shape[0]]\n",
    "\n",
    "# Drop columns with more than 20% zeros\n",
    "sensor_data = sensor_data.drop(list(zero_20_pct.index), axis=1)\n",
    "sensor_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is now almost ready for modeling. We deal with class inbalance and feature standardization after splitting the data into test and training sets.\n",
    "\n",
    "### Feature standardization\n",
    "We choose RobustScaler over StandardScaler due to the skewness of a significant number of features in the data set, as determined in Milestone 1. Because StandardScaler must compute the mean and standard deviation, it is susceptible to outliers. On the other hand, RobustScaler is based on percentiles and, hence, is less susceptible to outliers. We now apply RobustScaler to our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>...</th>\n",
       "      <th>s577</th>\n",
       "      <th>s578</th>\n",
       "      <th>s583</th>\n",
       "      <th>s584</th>\n",
       "      <th>s585</th>\n",
       "      <th>s586</th>\n",
       "      <th>s587</th>\n",
       "      <th>s588</th>\n",
       "      <th>s589</th>\n",
       "      <th>s590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-1.322</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.049</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.735</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1.706</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.452</td>\n",
       "      <td>1.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.705</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>0.630</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953</td>\n",
       "      <td>-0.814</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.422</td>\n",
       "      <td>2.674</td>\n",
       "      <td>3.464</td>\n",
       "      <td>3.290</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>-4.514</td>\n",
       "      <td>94.449</td>\n",
       "      <td>100.900</td>\n",
       "      <td>97.651</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.724</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-1.184</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      s1     s2     s3     s4     s5     s7     s8     s9    s10    s11  ...  \\\n",
       "0  0.937 -0.398  0.794  0.352 -0.973  0.126  0.852  0.332  0.042 -1.322  ...   \n",
       "1 -0.875  0.705 -0.396  0.815  0.386 -0.916  0.630 -0.170  0.281  0.078  ...   \n",
       "2 -0.252 -0.226 -0.055 -0.741  0.007  0.414 -0.259  0.252 -0.578 -0.322  ...   \n",
       "3  0.231  0.041  0.873  0.082  0.432 -0.170  0.407  0.393 -0.094 -0.661  ...   \n",
       "4 -0.724 -0.773  0.873  0.082  0.432 -0.170  0.407  0.636  0.937  0.443  ...   \n",
       "\n",
       "    s577   s578   s583   s584    s585   s586   s587  s588   s589   s590  \n",
       "0 -1.049 -0.523  0.380  1.735   1.900  1.706 -0.769 0.546  0.452  1.937  \n",
       "1  0.953 -0.814 -0.983  0.388   0.300  0.422  2.674 3.464  3.290  0.156  \n",
       "2  0.271 -0.938 -0.268 -0.714  -1.100 -0.711 -0.021 0.010 -0.065  0.028  \n",
       "3  0.071 -0.510 -4.514 94.449 100.900 97.651 -0.021 0.010 -0.065  0.028  \n",
       "4  0.088 -0.008 -1.184  1.041   0.800  1.082  0.966 0.031  0.194 -0.396  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale data\n",
    "scaler = RobustScaler()\n",
    "sensor_data = pd.DataFrame(scaler.fit_transform(sensor_data), \n",
    "                           columns=sensor_data.columns)\n",
    "\n",
    "# Display scaled data set\n",
    "sensor_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test\n",
    "We now split the data into training and test data sets, reserving ten percent of the rows for testing (157 rows) and using the rest to train our models. We choose this relatively high number to ensure that a sufficient number of positives exist in the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 1252 rows.\n",
      "Test data has 314 rows.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(sensor_data, \n",
    "                     sensor_labels_data['result'], \n",
    "                     test_size = 0.2,\n",
    "                     random_state = 0)\n",
    "\n",
    "# Describe training and test\n",
    "print(\"Training data has {} rows.\".format(X_train.shape[0]))\n",
    "print(\"Test data has {} rows.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the test data has been isolated, we can deal with class inbalance and feature standardization in the training data.\n",
    "\n",
    "### Balance classes using class weights\n",
    "To address class inbalance we are not using oversampling as in previous iterations of this project. Instead, we pass a dictionary of class weights to the fit() method on the model (below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to our results from Milestone 1 to select the features for our models.\n",
    "\n",
    "### Feature selection\n",
    "In Milestone 1, we applied four different methods to select the best features from our large set of features. Since stepwise (forward) selection produced the features with the most correlation with the other methods, we will go with the twenty best features chosen by this method:\n",
    "\n",
    "1. s22\n",
    "1. s34\n",
    "1. s65\n",
    "1. s104\n",
    "1. s125\n",
    "1. s130\n",
    "1. s144\n",
    "1. s189\n",
    "1. s313\n",
    "1. s438\n",
    "\n",
    "We select these features here for use below in the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise-selected features from Milestone 1\n",
    "stepwise_features = ['s22', 's34', 's65', 's104', 's125', 's130', 's144', 's189', 's313', 's438']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our training data set has been resampled and standardized and we have selected our features, we are ready to proceed to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a simple neural networks model\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a DNN model\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare class weights to balance classes\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "\n",
    "# Create class-weights dictionary\n",
    "class_weights = dict(zip([-1, 1], class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu, input_dim = 401),\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation = tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer = 'sgd', \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1252/1252 [==============================] - 0s 368us/sample - loss: 18.3788 - acc: 0.0727\n",
      "Epoch 2/10\n",
      "1252/1252 [==============================] - 0s 104us/sample - loss: 17.5709 - acc: 0.0727\n",
      "Epoch 3/10\n",
      "1252/1252 [==============================] - 0s 113us/sample - loss: 17.2662 - acc: 0.0727\n",
      "Epoch 4/10\n",
      "1252/1252 [==============================] - 0s 104us/sample - loss: 17.2776 - acc: 0.0727\n",
      "Epoch 5/10\n",
      "1252/1252 [==============================] - 0s 106us/sample - loss: 17.4787 - acc: 0.0727\n",
      "Epoch 6/10\n",
      "1252/1252 [==============================] - 0s 107us/sample - loss: 17.8821 - acc: 0.0727\n",
      "Epoch 7/10\n",
      "1252/1252 [==============================] - 0s 110us/sample - loss: 16.9528 - acc: 0.0727\n",
      "Epoch 8/10\n",
      "1252/1252 [==============================] - 0s 106us/sample - loss: 17.8189 - acc: 0.0727\n",
      "Epoch 9/10\n",
      "1252/1252 [==============================] - 0s 111us/sample - loss: 17.4310 - acc: 0.0727\n",
      "Epoch 10/10\n",
      "1252/1252 [==============================] - 0s 106us/sample - loss: 17.8033 - acc: 0.0727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x322d3fd448>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train, \n",
    "          epochs = 10, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 666us/sample - loss: 30.5647 - acc: 0.0414\n",
      "Test accuracy: 0.041401275\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Display accuracy\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a RNN model\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summarize your findings\n",
    "TODO: Summarize your findings with examples. Explain what the manufacturer should focus on to optimize\n",
    "the diaper manufacturing process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
