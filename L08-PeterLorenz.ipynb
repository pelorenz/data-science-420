{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 08\n",
    "# Peter Lorenz\n",
    "\n",
    "## 0. Preparation\n",
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Display multiple cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Initializes parameters to random values\n",
    "def init_parameters(dim1, dim2 = 1, std = 1e-1, random = True):\n",
    "    if(random):\n",
    "        return(np.random.random([dim1, dim2]) * std)\n",
    "    else:\n",
    "        return(np.zeros([dim1, dim2]))\n",
    "\n",
    "# Perform forward pass\n",
    "def forward(W1, bias, X):\n",
    "    Z1 = np.dot(X, W1) + bias\n",
    "    A1 = sigmoid(Z1)\n",
    "    return(A1)\n",
    "\n",
    "# Perform backward pass\n",
    "def backward(A1, W1, bias, X, Y):\n",
    "    m = np.shape(X)[0] # used the calculate the cost by the number of inputs -1/m\n",
    "   \n",
    "    loss = Y * np.log(A1) + (1 - Y)*np.log(1 - A1)           # loss at each row\n",
    "    cost = (-1/m) * np.sum(loss)                             # loss across all rows\n",
    "    dZ1 = A1 - Y                                             # derivative of loss wrt Z1\n",
    "    dW1 = (1/m) * np.dot(X.T, dZ1)                           # derivative of loss wrt weights\n",
    "    dBias = (1/m) * np.sum(dZ1, axis = 0, keepdims = True) # derivative of loss wrt bias\n",
    "    \n",
    "    # Homework: measure derivative loss with respect to Z2 then Z1\n",
    "    \n",
    "    \n",
    "    grads = {\"dW1\": dW1, \"dB1\": dBias}                       # updated weights and biases\n",
    "    \n",
    "    return(grads, cost)\n",
    "\n",
    "# Perform gradient descent\n",
    "def run_grad_desc(num_epochs, learning_rate, X, Y):\n",
    "    \n",
    "    m, input_cols = X.shape\n",
    "    \n",
    "    W1 = init_parameters(input_cols, output_cols)\n",
    "    B1 = init_parameters(output_cols)\n",
    "    \n",
    "    loss_array = np.ones([num_epochs])*np.nan     # place-holder of keeping track of loss\n",
    "    \n",
    "    for i in np.arange(num_epochs):\n",
    "        A1 = forward(W1, B1, X)                   # get activations in final layer\n",
    "        grads, cost = backward(A1, W1, B1, X, Y)  # get gradient and the cost from BP \n",
    "        \n",
    "        W1 = W1 - learning_rate*grads[\"dW1\"]      # update weights\n",
    "        B1 = B1 - learning_rate*grads[\"dB1\"]      # update bias\n",
    "        \n",
    "        loss_array[i] = cost                      # record loss for current iteration\n",
    "        \n",
    "        parameter = {\"W1\": W1, \"B1\": B1}          # record parameters for current iteration\n",
    "    \n",
    "    return(parameter, loss_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use the provided RedWhiteWine.csv file\n",
    "In this section, we load and prepare the provided RedWhiteWine.csv file. We include all features, using “Class” as the output vector. First we read and prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 13)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.400</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>3.510</td>\n",
       "      <td>0.560</td>\n",
       "      <td>9.400</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.800</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.680</td>\n",
       "      <td>9.800</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.800</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2.300</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>3.260</td>\n",
       "      <td>0.650</td>\n",
       "      <td>9.800</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.200</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>3.160</td>\n",
       "      <td>0.580</td>\n",
       "      <td>9.800</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.400</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>3.510</td>\n",
       "      <td>0.560</td>\n",
       "      <td>9.400</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          7.400             0.700        0.000           1.900      0.076   \n",
       "1          7.800             0.880        0.000           2.600      0.098   \n",
       "2          7.800             0.760        0.040           2.300      0.092   \n",
       "3         11.200             0.280        0.560           1.900      0.075   \n",
       "4          7.400             0.700        0.000           1.900      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0               11.000                34.000    0.998 3.510      0.560   \n",
       "1               25.000                67.000    0.997 3.200      0.680   \n",
       "2               15.000                54.000    0.997 3.260      0.650   \n",
       "3               17.000                60.000    0.998 3.160      0.580   \n",
       "4               11.000                34.000    0.998 3.510      0.560   \n",
       "\n",
       "   alcohol  quality  Class  \n",
       "0    9.400        5      1  \n",
       "1    9.800        5      1  \n",
       "2    9.800        5      1  \n",
       "3    9.800        6      1  \n",
       "4    9.400        5      1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6497 non-null   float64\n",
      " 1   volatile acidity      6497 non-null   float64\n",
      " 2   citric acid           6497 non-null   float64\n",
      " 3   residual sugar        6497 non-null   float64\n",
      " 4   chlorides             6497 non-null   float64\n",
      " 5   free sulfur dioxide   6497 non-null   float64\n",
      " 6   total sulfur dioxide  6497 non-null   float64\n",
      " 7   density               6497 non-null   float64\n",
      " 8   pH                    6497 non-null   float64\n",
      " 9   sulphates             6497 non-null   float64\n",
      " 10  alcohol               6497 non-null   float64\n",
      " 11  quality               6497 non-null   int64  \n",
      " 12  Class                 6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Internet location of the data set\n",
    "url = \"https://library.startlearninglabs.uw.edu/DATASCI420/2019/Datasets/RedWhiteWine.csv\"\n",
    "\n",
    "# Download the data into a dataframe object\n",
    "wine_data = pd.read_csv(url)\n",
    "\n",
    "# Display shape and initial data\n",
    "wine_data.shape\n",
    "wine_data.head()\n",
    "\n",
    "# Examine column types\n",
    "wine_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set aside the output variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 12)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set aside the output variable\n",
    "output = wine_data['Class']\n",
    "\n",
    "# Drop output from main data frame\n",
    "wine_data = wine_data.drop('Class', axis=1)\n",
    "wine_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we scale the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142</td>\n",
       "      <td>2.189</td>\n",
       "      <td>-2.193</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-1.446</td>\n",
       "      <td>1.035</td>\n",
       "      <td>1.813</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.451</td>\n",
       "      <td>3.282</td>\n",
       "      <td>-2.193</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>1.198</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>0.701</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>-0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.451</td>\n",
       "      <td>2.553</td>\n",
       "      <td>-1.918</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>1.027</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>-0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.074</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>1.661</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.541</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>1.102</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142</td>\n",
       "      <td>2.189</td>\n",
       "      <td>-2.193</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-1.446</td>\n",
       "      <td>1.035</td>\n",
       "      <td>1.813</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          0.142             2.189       -2.193          -0.745      0.570   \n",
       "1          0.451             3.282       -2.193          -0.598      1.198   \n",
       "2          0.451             2.553       -1.918          -0.661      1.027   \n",
       "3          3.074            -0.362        1.661          -0.745      0.541   \n",
       "4          0.142             2.189       -2.193          -0.745      0.570   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
       "0               -1.100                -1.446    1.035  1.813      0.193   \n",
       "1               -0.311                -0.862    0.701 -0.115      1.000   \n",
       "2               -0.875                -1.092    0.768  0.258      0.798   \n",
       "3               -0.762                -0.986    1.102 -0.364      0.328   \n",
       "4               -1.100                -1.446    1.035  1.813      0.193   \n",
       "\n",
       "   alcohol  quality  \n",
       "0   -0.915   -0.937  \n",
       "1   -0.580   -0.937  \n",
       "2   -0.580   -0.937  \n",
       "3   -0.580    0.208  \n",
       "4   -0.915   -0.937  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "wine_data = pd.DataFrame(scaler.fit_transform(wine_data), \n",
    "                         columns=wine_data.columns)\n",
    "\n",
    "# Display scaled data set\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for building our network, we partition the data set into training and test data, reserving 10% of the data for test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 3248 rows.\n",
      "Test data has 3249 rows.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    output, \n",
    "                                                    test_size = 0.5,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Convert output to arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Describe training and test data sets\n",
    "print(\"Training data has {} rows.\".format(X_train.shape[0]))\n",
    "print(\"Test data has {} rows.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Develop multi-layer feed-forward/backpropagation neural network\n",
    "In this section, we use the provided Simple Perceptron Neural Network notebook to develop a multi-layer feed-forward/backpropagation neural network. We begin with a single forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions: (3248, 12) * (12, 1) + (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.565],\n",
       "       [0.563],\n",
       "       [0.536],\n",
       "       ...,\n",
       "       [0.527],\n",
       "       [0.537],\n",
       "       [0.476]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data set dimensions\n",
    "_, input_cols = X_train.shape\n",
    "\n",
    "# only one output column\n",
    "output_cols = 1\n",
    "\n",
    "# Initialize parameters\n",
    "weights = init_parameters(input_cols, output_cols)\n",
    "bias = init_parameters(output_cols)\n",
    "\n",
    "# Display dimensions\n",
    "print(\"Checking dimensions: {} * {} + {}\".format(X_train.shape, weights.shape, bias.shape))\n",
    "\n",
    "# Perform forward pass and display predictions\n",
    "pred = forward(weights, bias, X_train)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we test the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dW1': array([[ 0.005,  0.005,  0.006, ...,  0.005,  0.005,  0.005],\n",
       "        [ 0.019,  0.019,  0.018, ...,  0.019,  0.019,  0.019],\n",
       "        [ 0.001,  0.001,  0.001, ...,  0.001,  0.001,  0.001],\n",
       "        ...,\n",
       "        [ 0.017,  0.017,  0.017, ...,  0.017,  0.017,  0.017],\n",
       "        [-0.005, -0.005, -0.003, ..., -0.005, -0.005, -0.005],\n",
       "        [-0.003, -0.003, -0.002, ..., -0.003, -0.003, -0.003]]),\n",
       " 'dB1': array([[ 0.501,  0.501, -0.499, ...,  0.501,  0.501,  0.501]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform backward pass\n",
    "gradients, _ = backward(pred, weights, bias, X_train, y_train)\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our functions tested, we perform gradient descent for 1000 iterations to see our neural network in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gradient descent\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "params, loss_array = run_grad_desc(num_epochs, learning_rate, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.429 -0.429  0.458 ... -0.429 -0.429 -0.429]\n",
      "[0.016 0.016 0.016 ... 0.04  0.04  0.04 ]\n"
     ]
    }
   ],
   "source": [
    "# Display final parameters\n",
    "print(params['B1'][0])\n",
    "print(params['W1'].ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we display the predictions from our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5847"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params['B1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute final predictions from training params\n",
    "Y_pred_nn = forward(params['W1'], params['B1'], X_train)[0]\n",
    "\n",
    "# Convert probabilities to binary\n",
    "Y_pred_nn = np.where(Y_pred_nn > 0.5, 1, 0)\n",
    "\n",
    "# Compare predictions to actual\n",
    "np.hstack([Y_pred_nn, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute final predictions from training params\n",
    "y_pred = forward(params['W1'], params['B1'], X_test)[0]\n",
    "\n",
    "# Convert probabilities to binary\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "# Compare predictions to actual\n",
    "np.hstack([y_pred, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [650, 5847]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-88bcd919393d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Display confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Display performance metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [650, 5847]"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Display performance metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x62d2784e08>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss per epoch\n",
    "sns.lineplot(data = loss_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our initial neural network, we are ready to experiment with the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adjust the following between experiments:\n",
    "In this section, we adjust various settings and run experiments.\n",
    "\n",
    "### Learning Rate\n",
    "In this section, we adjust the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs\n",
    "In this section, we adjust the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth of architecture\n",
    "In this section, we adjust the depth of the architecture, that is, the number of hidden layers between the input and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes per hidden layer\n",
    "In this section, we adjust the number of nodes in a hidden layer, the width of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determine best neural network structure and settings\n",
    "In this section, we determine the best neural network structure and hyperparameter settings, resulting in the best predictive capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this assignment, we ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
