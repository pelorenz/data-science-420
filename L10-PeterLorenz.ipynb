{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10\n",
    "# Peter Lorenz\n",
    "\n",
    "## 0. Preparation\n",
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display multiple cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare constants\n",
    "EMBEDDING_VECOR_LENGTH = 250\n",
    "NUM_WORDS = 5000\n",
    "MAX_LEN = 500\n",
    "MAX_REVIEW_LENGTH = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data set into training and testing\n",
    "In this section we read the Reuters data set into training and test data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with pickle bug\n",
    "# See https://stackoverflow.com/questions/57176714/how-to-fix-error-when-load-dataset-in-keras\n",
    "old = np.load\n",
    "np.load = lambda *a,**k: old(*a,allow_pickle=True)\n",
    "\n",
    "# Load data set\n",
    "(X_train, y_train), (X_test, y_test) = \\\n",
    "    tf.keras.datasets.reuters.load_data(\n",
    "        path='reuters.npz', num_words=NUM_WORDS, skip_top=10, maxlen=MAX_LEN, \n",
    "        test_split=0.2, seed=1)\n",
    "\n",
    "# Restore numpy load\n",
    "np.load = old\n",
    "del(old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the shape of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8621,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2156,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(8621,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2156,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine data\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the data set\n",
    "In this section we prepare the data set. We begin by padding the sequences in the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad data\n",
    "x_train_padded = pad_sequences(X_train, maxlen = MAX_REVIEW_LENGTH)\n",
    "x_test_padded = pad_sequences(X_test, maxlen = MAX_REVIEW_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we verify the shape of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8621, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2156, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display shape\n",
    "x_train_padded.shape\n",
    "x_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check we examine the padded data itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    2, 2949,  341,  704,   44,\n",
       "         26,   14,  704,   44,   26,  255,  219,   91,   68,  146,   93,\n",
       "         59,   17,   12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data prepared, we can now build our models.\n",
    "\n",
    "## 3. Build and compile 3 different models\n",
    "In this section we build and compile 3 different models using Keras LTSM, ideally improving model at each iteration.\n",
    "\n",
    "### Model 1\n",
    "Our first model is a basic recurrent neural network with a single hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 250)          1250000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                36224     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                1518      \n",
      "=================================================================\n",
      "Total params: 1,287,742\n",
      "Trainable params: 1,287,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(NUM_WORDS, EMBEDDING_VECOR_LENGTH, \n",
    "                                 input_length = MAX_REVIEW_LENGTH))\n",
    "model.add(keras.layers.LSTM(32))\n",
    "model.add(keras.layers.Dense(46, activation = 'sigmoid'))\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', \n",
    "              metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8621 samples, validate on 2156 samples\n",
      "Epoch 1/2\n",
      "8621/8621 [==============================] - 54s 6ms/sample - loss: 3.3708 - acc: 0.3476 - val_loss: 2.7891 - val_acc: 0.3762\n",
      "Epoch 2/2\n",
      "8621/8621 [==============================] - 54s 6ms/sample - loss: 2.5956 - acc: 0.3621 - val_loss: 2.3747 - val_acc: 0.3762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xed821d7148>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train, validation_data = (x_test_padded, y_test), \n",
    "          epochs = 2, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model trained, we check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156/2156 [==============================] - 5s 2ms/sample - loss: 2.3747 - acc: 0.3762\n",
      "Accuracy: 37.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "scores = model.evaluate(x_test_padded, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of our initial model is rather poor with just 38% accuracy.\n",
    "\n",
    "### Model 2\n",
    "Next we try a second model with an additional hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 300, 250)          1250000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                36224     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 92)                3036      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46)                4278      \n",
      "=================================================================\n",
      "Total params: 1,293,538\n",
      "Trainable params: 1,293,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.Embedding(NUM_WORDS, EMBEDDING_VECOR_LENGTH, \n",
    "                                  input_length = MAX_REVIEW_LENGTH))\n",
    "model2.add(keras.layers.LSTM(32))\n",
    "model2.add(keras.layers.Dense(92, activation = 'relu'))\n",
    "model2.add(keras.layers.Dense(46, activation = 'sigmoid'))\n",
    "model2.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', \n",
    "               metrics = ['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8621 samples, validate on 2156 samples\n",
      "Epoch 1/2\n",
      "8621/8621 [==============================] - 55s 6ms/sample - loss: 3.1566 - acc: 0.3410 - val_loss: 2.4540 - val_acc: 0.3762\n",
      "Epoch 2/2\n",
      "8621/8621 [==============================] - 55s 6ms/sample - loss: 2.4179 - acc: 0.3621 - val_loss: 2.2178 - val_acc: 0.3762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xed826b7408>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train_padded, y_train, validation_data = (x_test_padded, y_test), \n",
    "           epochs = 2, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156/2156 [==============================] - 5s 2ms/sample - loss: 2.2178 - acc: 0.3762\n",
      "Accuracy: 37.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "scores = model2.evaluate(x_test_padded, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an additional hidden layer did not improve the model accuracy, which remains at about 38%.\n",
    "\n",
    "## Model 3\n",
    "We now try a third model by experimenting with various hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Describe and explain your findings\n",
    "In this assignment ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
